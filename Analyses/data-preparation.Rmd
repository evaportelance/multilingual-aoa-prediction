---
title: "data-preparation"
author: "Eva Portelance"
date: "8/10/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
options(dplyr.summarise.inform = FALSE)

# load libraries
library(arm)
library(tidyverse)
library(glue)
library(wordbankr)
#install.packages("remotes")
#remotes::install_github("langcog/childesr")
library(childesr)
library(broom)
library(car)
#library(jglmm)
library(modelr)
library(ggrepel)
library(SnowballC)
library(stringr)
library(ggplot2)
library(tm)
library(sjPlot)
library(sjlabelled)
library(sjmisc)
theme_set(theme_sjplot())


# load functions

walk(list.files("scripts", pattern = "*.R$", full.names = TRUE), source)
```



# Load Wordbank data

Loading cached Wordbank data for multiple languages:
```{r loadwordbankxling}
target_langs <- c("French (Quebecois)", "German", "English (American)", "Spanish (Mexican)","Mandarin (Beijing)", "French (French)", "English (Australian)", "English (British)", "Mandarin (Taiwanese)", "Spanish (European)" )



wb_data <- map_df(target_langs, function(lang) {
  print(glue("Loading data for {lang}..."))
  norm_lang <- normalize_language(lang)
  tryCatch( 
    {
      # If data for language X is already cashed, it will be loaded directly into the workspace
      readRDS(glue("./data/wordbank/{norm_lang}.rds"))
    },
    error = function(e) {
      # If the data for language X is not cashed, it will download it for all available instruments types, cashe the data for future use and then load it into the workspace
      print(glue("No cashed data for {lang}, downloading data now..."))
      create_wb_data(lang)
      readRDS(glue("./data/wordbank/{norm_lang}.rds"))
    }
    )

})

```

# Load predictors

Merge in the by-concept predictors (concreteness) to the unilemmas.

```{r merge_unilemmas}
uni_lemmas <- extract_uni_lemmas(wb_data)
```

```{r load_predictors}
concreteness_map <- c(word = "Word", concreteness = "Conc.M")
concreteness <- uni_lemmas |> map_predictor("concreteness", concreteness_map)
```

Load frequency 

```{r load_freq}
frequencies <- readRDS("./data/surprisal-and-frequency/frequencies.rds")
frequencies <- frequencies |> select(-c(n_train_instances, n_val_instances, n_total, train_frequency))
```

Load surprisal and perplexity values
```{r load_model_surprisals}
lstm_surprisals <- readRDS("./data/surprisal-and-frequency/lstm_surprisals.rds")
lstm_surprisals <- lstm_surprisals |> mutate(lstm_surprisal = avg_surprisal) |> select(-c(n_instances, avg_surprisal)) |> unique()
```

```{r load_ngram_suprisals}
ngram_surprisals <- readRDS("./data/surprisal-and-frequency/ngram_childes_surprisal.rds")
ngram_surprisals <- ngram_surprisals |> select(-c(cnt, frequency, avg_surprisal))
```


Combine all predictors by unilemma
```{r combine_all}
predictor_data <- ngram_surprisals |> left_join(lstm_surprisals) |> left_join(frequencies) |> left_join(concreteness)
```


Set lexical contrasts and predictors list

```{r lex_contrast}
data_lexcat <- prep_lexcat(predictor_data, uni_lemmas, "nouns")

predictor_sources <- list(
  c("lstm_surprisal", "all_frequency", "surprisal_2gm", "surprisal_3gm", "surprisal_4gm"),
  "concreteness")
predictors <- unlist(predictor_sources)
```

Remove items with NA data points

```{r remove_NA}
remove_NA_predictors <- function(data, predictors){
  for (pred in predictors){
    data <- data |> filter(!is.na(data[[pred]]))
  }
  return(data)
}
```


Get fitted AoAs
```{r aoa-lm}
aoas <- fit_aoas(wb_data)
# All items or only items that are single word expressions
aoa_predictor_data <- aoas |> left_join(data_lexcat) |> remove_NA_predictors(predictors)

#concreteness_ratings <- aoa_predictor_data |> filter(lexical_category == "function_words") |> select(c(uni_lemma, concreteness)) |> unique() 
#mean(concreteness_ratings$concreteness) 
#sd(concreteness_ratings$concreteness)

saveRDS(aoa_predictor_data, "./data/aoa_predictor_data.rds" )
#aoa_predictor_data <- readRDS("./data/aoa_predictor_data.rds" )

aoa_predictor_data %>% unique() %>% group_by(measure,language,uni_lemma,definition) %>% mutate(surprisal_1gm = - log(all_frequency)) %>% mutate_at(vars(starts_with("surprisal"),lstm_surprisal,avg_perplexity), ~sum(.*all_frequency)/sum(all_frequency)) %>% mutate(all_frequency=sum(all_frequency)) %>% select(-word_clean) %>% unique() %>% ungroup() %>% saveRDS("./data/aoa_predictor_data_unify.rds") #%>% mutate(cnt_lex = length(unique(lexical_class)), cnt_cat = length(unique(category))) %>% arrange(desc(cnt_cat)) #%>% select(measure,language,uni_lemma,definition,lexical_class) %>% unique()

#aoa_predictor_data <- readRDS("./data/aoa_predictor_data_unify.rds" )
```
