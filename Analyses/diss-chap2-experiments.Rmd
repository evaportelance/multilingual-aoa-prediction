---
title: "diss-chap2-experiments"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
options(dplyr.summarise.inform = FALSE)

# load libraries
library(arm)
library(tidyverse)
library(glue)
library(wordbankr)
#install.packages("remotes")
#remotes::install_github("langcog/childesr")
library(childesr)
library(broom)
library(car)
#library(jglmm)1
library(modelr)
library(ggrepel)
library(SnowballC)
library(stringr)
library(ggplot2)
library(tm)


# load functions

walk(list.files("scripts", pattern = "*.R$", full.names = TRUE), source)
```

# Load Wordbank data

Loading cached Wordbank data for multiple languages:
```{r loadwordbankxling}
target_langs <- c("French (Quebecois)", "German", "English (American)", "Spanish (Mexican)","Mandarin (Beijing)", "French (French)", "English (Australian)", "English (British)", "Mandarin (Taiwanese)", "Spanish (European)" )



wb_data <- map_df(target_langs, function(lang) {
  print(glue("Loading data for {lang}..."))
  norm_lang <- normalize_language(lang)
  tryCatch( 
    {
      # If data for language X is already cashed, it will be loaded directly into the workspace
      readRDS(glue("./data/wordbank/{norm_lang}.rds"))
    },
    error = function(e) {
      # If the data for language X is not cashed, it will download it for all available instruments types, cashe the data for future use and then load it into the workspace
      print(glue("No cashed data for {lang}, downloading data now..."))
      create_wb_data(lang)
      readRDS(glue("./data/wordbank/{norm_lang}.rds"))
    }
    )

})

```

# Load predictors

Merge in the by-concept predictors (concreteness) to the unilemmas.

```{r merge_unilemmas}
uni_lemmas <- extract_uni_lemmas(wb_data)
```

```{r load_predictors}
concreteness_map <- c(word = "Word", concreteness = "Conc.M")
concreteness <- uni_lemmas |> map_predictor("concreteness", concreteness_map)
```

Load frequency 

```{r load_freq}
frequencies <- readRDS("./data/surprisal-and-frequency/frequencies.rds")
frequencies <- frequencies |> select(-c(n_train_instances, n_val_instances, n_total, train_frequency))
```

Load surprisal and perplexity values
```{r load_model_surprisals}
lstm_surprisals <- readRDS("./data/surprisal-and-frequency/lstm_surprisals.rds")
lstm_surprisals <- lstm_surprisals |> mutate(lstm_surprisal = avg_surprisal) |> select(-c(n_instances, avg_surprisal)) |> unique()
```

```{r load_ngram_suprisals}
ngram_surprisals <- readRDS("./data/surprisal-and-frequency/ngram_childes_surprisal.rds")
ngram_surprisals <- ngram_surprisals |> select(-c(cnt, frequency, avg_surprisal))
```


Combine all predictors by unilemma
```{r combine_all}
predictor_data <- ngram_surprisals |> left_join(lstm_surprisals) |> left_join(frequencies) |> left_join(concreteness)
```


Set lexical contrasts and predictors list

```{r lex_contrast}
data_lexcat <- prep_lexcat(predictor_data, uni_lemmas, "nouns")

predictor_sources <- list(
  c("lstm_surprisal", "all_frequency", "surprisal_2gm", "surprisal_3gm", "surprisal_4gm"),
  "concreteness")
predictors <- unlist(predictor_sources)
```

Remove items with NA data points

```{r remove_NA}
remove_NA_predictors <- function(data, predictors){
  for (pred in predictors){
    data <- data |> filter(!is.na(data[[pred]]))
  }
  return(data)
}
```


Get fitted AoAs
```{r aoa-lm}
aoas <- fit_aoas(wb_data)
# All items or only items that are single word expressions
aoa_predictor_data <- aoas |> left_join(data_lexcat) |> remove_NA_predictors(predictors)

#concreteness_ratings <- aoa_predictor_data |> filter(lexical_category == "function_words") |> select(c(uni_lemma, concreteness)) |> unique() 
#mean(concreteness_ratings$concreteness) 
#sd(concreteness_ratings$concreteness)

#saveRDS(aoa_predictor_data, "./surprisals/aoa_predictor_data.rds" )
```

# Experiments

## EXPERIMENT 1 from chapter 2 of dissertation
Compare different predictor combination, especially surprisal and frequency, using cross validation for each language. Here I use LSTM surprisal.

Define models to compare
```{r formulae2}
all_full = ~ lexical_category * lstm_surprisal + lexical_category * all_frequency + lexical_category * concreteness
freq_full = ~ lexical_category * all_frequency + lexical_category * concreteness
null_model = ~ 1
formulae <- formulas(~aoa, null_model, all_full, freq_full)
```
When I try to run cross validation on all languages and measures simultaneously using map, R crashes, so you have to run each language manually one at a time and then combine them. Here we prep and scale the data for one language

START - RUN FOR EACH LANGUAGE

```{r prep_data2}
lang = "English (American)"
ms = "produces"

predictors <- c("lstm_surprisal", "all_frequency", "concreteness")

scaled_lang_data <- aoa_predictor_data |>
  filter(language==lang & measure==ms) |>
  select(language, uni_lemma, category, definition, word_clean, aoa, lexical_category, lstm_surprisal, all_frequency, concreteness) |>
  unique() |> mutate_at(vars(predictors), ~as.numeric(base::scale(.))) |>
  mutate(lexical_category = factor(lexical_category, levels = c("nouns", "predicates" , "function_words"),
                 labels = c("nouns", "predicates" , "function_words")))

```

```{r cor_vif1}
#Get correlation plot
cor_data <- scaled_lang_data %>% ungroup() %>% select(lstm_surprisal, all_frequency, concreteness)
cor(cor_data)

#polyserial(cor_data$concreteness, cor_data$lexical_category)

#Do colinearity analysis
model = lm(aoa ~ lstm_surprisal + all_frequency + concreteness + lexical_category, data=scaled_lang_data)
car::vif(model)
```

Run cross-validation for a single language.
```{r cross_validate2}
loo_df <- crossv_loo(scaled_lang_data)

fit_cv_models_single <- function(id) {
  models <- "no model"
  train_idx <- loo_df[id,1][[1]][[1]]$idx
  test_idx <- loo_df[id,2][[1]][[1]]$idx
  train_df <- scaled_lang_data[train_idx,]

  try(models <- fit_with(train_df, lm, formulae))

  result <- enframe(models) |>
    mutate(model = value,
           train = list(train_idx),
           test = list(test_idx)) |>
    select(-c(value))

  return(result)
}

# dont try to view
loo_models <- loo_df$.id |>
    map(fit_cv_models_single) |>
    reduce(rbind)

# dont try to view
loo_preds <- get_cv_preds(loo_models, scaled_lang_data) |> 
  mutate(language = lang,
         measure = ms)
# View
cv_results <- get_cv_results(loo_preds) |>
    mutate(language = lang,
         measure = ms)

cv_results_pos <- loo_preds |>
  group_by(language, measure, name, lexical_category) |>
  summarise(mean_abs_dev = mean(abs_dev), sd_ads_dev = sd(abs_dev))

```

Check if difference between all_full, freq_full, and null models are significant using ANOVA
```{r anova2}
null_model <- lm(formula= aoa ~ 1, data = scaled_lang_data)
model_base <- lm(formula= aoa ~ lexical_category * all_frequency + lexical_category * concreteness, data = scaled_lang_data)
model_augmented <- lm(formula = aoa ~ lexical_category * lstm_surprisal + lexical_category * all_frequency + lexical_category * concreteness, data = scaled_lang_data)

anova(null_model, model_base)
anova(model_base, model_augmented)
```

Look at the relation between surprisal and aoa. First part is to look at coefficient estimate, second is to look at the effect of surprisal beyond frequency.

Get coefficient estimates for frequency and surprisal in the best model
```{r betas}
get_betas <- function(n){
  model = models$model[n]
  result <- tidy(model[[1]]) |> 
      mutate(fold = n)
  return(result)
}

models= loo_models |> filter(name=="all_full")  

models_betas = map(c(1:nrow(models)), get_betas) |> bind_rows()

lexcat_betas <- models_betas |> select(term, estimate, fold) |> spread(key=term, value=estimate) |>
  rename_with(removePunctuation) |>
  mutate(fctwd_surprisal = lstmsurprisal + lexicalcategoryfunctionwords + lexicalcategoryfunctionwordslstmsurprisal,
         pred_surprisal = lstmsurprisal + lexicalcategorypredicates + lexicalcategorypredicateslstmsurprisal,
         noun_surprisal = lstmsurprisal,
         noun_frequency = allfrequency,
         fctwd_frequency = allfrequency + lexicalcategoryfunctionwords + lexicalcategoryfunctionwordsallfrequency,
         pred_frequency = allfrequency + lexicalcategorypredicates + lexicalcategorypredicatesallfrequency,
         noun_concreteness = concreteness,
         fctwd_concreteness = concreteness + lexicalcategoryfunctionwords + lexicalcategoryfunctionwordsconcreteness,
         pred_concreteness = concreteness + lexicalcategorypredicates + lexicalcategorypredicatesconcreteness
         ) |> 
  select(noun_surprisal,fctwd_surprisal,pred_surprisal,noun_frequency, fctwd_frequency, pred_frequency, noun_concreteness, fctwd_concreteness, pred_concreteness) |> 
  gather(key="term", value="estimate") |> 
  separate(col=term, into=c("lexical_category", "term"), sep="_") |>
  mutate(language = lang,
         measure = ms)


#lex.labs <- c("function words", "nouns", "predicates")
#names(lex.labs) <- c("fctwd", "noun", "pred")
#ggplot(lexcat_betas, aes(x = estimate, y = term, colour = term, fill=term)) +
#  facet_grid(~ lexical_category, labeller = labeller(lexical_category = lex.labs)) +
#  geom_vline(xintercept = 0, color = "grey", linetype = "dotted") +
#  geom_point(alpha=0.2, position = position_jitter(w = 0, h = 0.1), show.legend = FALSE)+
#  labs(x = "Coefficient estimate", y = "") +
#  theme_bw() +
#  theme(text=element_text(size=18,  family="Times New Roman"), axis.text.x = element_text(size = 16), axis.text.y = element_text(size = 16))
```

Comparing a model with and without surprisal by word
```{r beyond_freq}
word_mad_diff <- loo_preds |> filter(name %in% c("freq_full", "all_full")) |> 
  group_by(name, test_word, lexical_category, aoa) |> summarise(mean(abs_dev)) |> 
  spread(key=name, value="mean(abs_dev)" ) |> 
  mutate(diff = freq_full-all_full) |> 
  arrange(desc(diff)) |>
  mutate(language = lang,
         measure = ms)

#ggplot(data = word_mad_diff |> arrange(desc(diff)) %>% head(50) , 
#            aes(x = reorder(test_word,diff), y = diff, fill=lexical_category)) +
#  geom_bar(stat='identity') +
#  coord_flip()+
#  labs(x="", y="difference in absolute deviation") +
#  theme_bw() +
#  theme(text=element_text(size=18,  family="Times New Roman"), legend.title = element_text( size = 16), legend.text = element_text( size = 16), legend.position = c(0.7, 0.6), axis.text.x = element_text(size = 16), axis.text.y = element_text(size = 16))
```

by lexical category
```{r lexcat_counts}
lexcat_mad_diff <- word_mad_diff |> group_by(lexical_category) |>
  summarise(mean_diff=mean(diff), n_lex =n()) |>
  mutate(language = lang,
         measure = ms)
```


```{r collect_data}
#first language
exp1_all_cv_results <- cv_results
exp1_all_cv_results_pos <- cv_results_pos

exp1_all_lexcat_betas <- lexcat_betas
exp1_all_word_mad_diffs <- word_mad_diff
exp1_all_lexcat_mad_diffs <- lexcat_mad_diff

#all subsequent languages
#exp1_all_cv_results <- exp1_all_cv_results |> rbind(cv_results)
#exp1_all_cv_results_pos <- exp1_all_cv_results_pos |> rbind(cv_results_pos)

#exp1_all_lexcat_betas <- exp1_all_lexcat_betas |> rbind(lexcat_betas)
#exp1_all_word_mad_diffs <- exp1_all_word_mad_diffs |> rbind(word_mad_diff)
#exp1_all_lexcat_mad_diffs <- exp1_all_lexcat_mad_diffs |> rbind(lexcat_mad_diff)

```

STOP - REPEAT EXPERIMENT FOR NEXT LANGUAGE

```{r save_data3}
saveRDS(exp1_all_cv_results, "./experiment-results/diss/exp1_all_cv_results.rds" )
saveRDS(exp1_all_cv_results_pos, "./experiment-results/diss/exp1_all_cv_results_pos.rds" )

saveRDS(exp1_all_lexcat_betas, "./experiment-results/diss/exp1_all_lexcat_betas.rds" )
saveRDS(exp1_all_word_mad_diffs, "./experiment-results/diss/exp1_all_word_mad_diffs.rds" )
saveRDS(exp1_all_lexcat_mad_diffs, "./experiment-results/diss/exp1_all_lexcat_mad_diffs.rds" )
```



## EXPERIMENT 2 from chapter 2 of dissertation

### Experiment 2.1: Compare different n-gram surprisal values using cross validation for each language

Define models to compare 
```{r formulae1}

lstm_surp = ~ lexical_category * lstm_surprisal + lexical_category * concreteness
four_surp = ~ lexical_category * surprisal_4gm + lexical_category * concreteness
tri_surp = ~ lexical_category * surprisal_3gm + lexical_category * concreteness
bi_surp = ~ lexical_category * surprisal_2gm + lexical_category * concreteness
uni_surp = ~ lexical_category * surprisal_1gm + lexical_category * concreteness
null_model = ~ 1
formulae <- formulas(~aoa, null_model, uni_surp, bi_surp, tri_surp, four_surp, lstm_surp)
```

When I try to run cross validation on all languages and measures simultaneously using map, R crashes, so you have to run each language manually one at a time and then combine them. Here we prep and scale the data for one language

START - RUN FOR EACH LANGUAGE

```{r prep_data1_log}
lang = "English (American)"
ms = "produces"

predictors <- c("lstm_surprisal", "surprisal_2gm", "surprisal_3gm", "surprisal_4gm", "concreteness", "surprisal_1gm")

scaled_lang_data <- aoa_predictor_data |>
  filter(language==lang & measure==ms) |>
  mutate(surprisal_1gm = - log(all_frequency)) |>
  select(language, uni_lemma, category, definition, word_clean, aoa, lexical_category, lstm_surprisal, surprisal_4gm, surprisal_3gm, surprisal_2gm, surprisal_1gm, concreteness) |>
  unique() |> mutate_at(vars(predictors), ~as.numeric(base::scale(.))) 
```

Check correlation between predictors
```{r cor_vif1}
#Get correlation plot
cor_data <- scaled_lang_data %>% ungroup() %>% select(lstm_surprisal, surprisal_4gm, surprisal_3gm, surprisal_2gm, surprisal_1gm, concreteness)
cor(cor_data, method = "pearson")

```

Run cross-validation for a single language.
```{r cross_validate1}
loo_df <- crossv_loo(scaled_lang_data)

fit_cv_models_single <- function(id) {
  models <- "no model"
  train_idx <- loo_df[id,1][[1]][[1]]$idx
  test_idx <- loo_df[id,2][[1]][[1]]$idx
  train_df <- scaled_lang_data[train_idx,]

  try(models <- fit_with(train_df, lm, formulae))

  result <- enframe(models) |>
    mutate(model = value,
           train = list(train_idx),
           test = list(test_idx)) |>
    select(-c(value))

  return(result)
}

# dont try to view
loo_models <- loo_df$.id |>
    map(fit_cv_models_single) |>
    reduce(rbind)

# dont try to view
loo_preds <- get_cv_preds(loo_models, scaled_lang_data) |> 
  mutate(language = lang,
         measure = ms)
# View
cv_results <- get_cv_results(loo_preds) |>
    mutate(language = lang,
         measure = ms)

cv_results_pos <- loo_preds |>
  group_by(language, measure, name, lexical_category) |>
  summarise(mean_abs_dev = mean(abs_dev), sd_ads_dev = sd(abs_dev))
```

```{r collect_data2}

#first language
exp2_all_cv_results_log <- cv_results
exp2_all_cv_results_pos_log <- cv_results_pos

#all subsequent languages
#exp2_all_cv_results_log <- exp2_all_cv_results_log |> rbind(cv_results)
#exp2_all_cv_results_pos_log <- exp2_all_cv_results_pos_log |> rbind(cv_results_pos)

```

STOP - REPEAT EXPERIMENT FOR NEXT LANGUAGE

```{r save_data1}
saveRDS(exp2_all_cv_results_log, "./experiment-results/diss/exp2_all_cv_results_log.rds" )
saveRDS(exp2_all_cv_results_pos_log, "./experiment-results/diss/exp2_all_cv_results_pos_log.rds" )
```


### Experiment 2.2 with residualized surprisal

Compare different model with and without residualized LSTM surprisa values using cross validation for each language

Define models to compare 
```{r formulae1}
lstm_surp_rd = ~ lexical_category * lstm_surp_resid + lexical_category * surprisal_1gm + lexical_category * concreteness
uni_surp = ~ lexical_category * surprisal_1gm + lexical_category * concreteness
null_model = ~ 1
formulae <- formulas(~aoa, lstm_surp_rd, uni_surp, null_model)
```

When I try to run cross validation on all languages and measures simultaneously using map, R crashes, so you have to run each language manually one at a time and then combine them. Here we prep and scale the data for one language

START - RUN FOR EACH LANGUAGE
```{r prep_data1_log}
lang = "English (American)"
ms = "produces"

predictors <- c("concreteness", "surprisal_1gm", "lstm_surprisal")

scaled_lang_data <- aoa_predictor_data |>
  filter(language==lang & measure==ms) |>
  mutate(surprisal_1gm = - log(all_frequency)) |>
  select(language, uni_lemma, category, definition, word_clean, aoa, lexical_category, lstm_surprisal, surprisal_1gm, concreteness) |>
  unique() |> mutate_at(vars(predictors), ~as.numeric(base::scale(.))) |>
  mutate(lstm_surp_resid = resid(lm(lstm_surprisal ~ surprisal_1gm))) |>
  mutate(lexical_category = factor(lexical_category, levels = c("nouns", "predicates" , "function_words"),
                 labels = c("nouns", "predicates" , "function_words")))
```

```{r cor}
#Get correlation plot
cor_data <- scaled_lang_data %>% ungroup() %>% select(lstm_surprisal, surprisal_1gm)
cor(cor_data, method = "pearson")
```

Run cross-validation for a single language.
```{r cross_validate1}
loo_df <- crossv_loo(scaled_lang_data)

# dont try to view
loo_models <- loo_df$.id |>
    map(fit_cv_models_single) |>
    reduce(rbind)

# dont try to view
loo_preds <- get_cv_preds(loo_models, scaled_lang_data) |> 
  mutate(language = lang,
         measure = ms)
# View
cv_results <- get_cv_results(loo_preds) |>
    mutate(language = lang,
         measure = ms)

cv_results_pos <- loo_preds |>
  group_by(language, measure, name, lexical_category) |>
  summarise(mean_abs_dev = mean(abs_dev), sd_ads_dev = sd(abs_dev))

```

Check if difference between base model and augmented model is significant using ANOVA
```{r anova2}
model_base <- lm(formula= aoa ~ lexical_category * surprisal_1gm + lexical_category * concreteness, data = scaled_lang_data)
model_augmented <- lm(formula = aoa ~ lexical_category * lstm_surp_resid + lexical_category * surprisal_1gm + lexical_category * concreteness, data = scaled_lang_data)

anova(model_base, model_augmented)
```

Get coefficients by lexical category for all cross validation folds
```{r betas}
get_betas <- function(n){
  model = models$model[n]
  result <- tidy(model[[1]]) |> 
      mutate(fold = n)
  return(result)
}

models= loo_models |> filter(name=="lstm_surp_rd")  

models_betas = map(c(1:nrow(models)), get_betas) |> bind_rows()

lexcat_betas <- models_betas |> select(term, estimate, fold) |> spread(key=term, value=estimate) |>
  rename_with(removePunctuation) |>
  mutate(
         pred_lstmresid = lstmsurpresid + lexicalcategorypredicates + lexicalcategorypredicateslstmsurpresid,
         noun_lstmresid = lstmsurpresid,
         fctwd_lstmresid = lstmsurpresid + lexicalcategoryfunctionwords + lexicalcategoryfunctionwordslstmsurpresid,
         fctwd_unigram = surprisal1gm + lexicalcategoryfunctionwords + lexicalcategoryfunctionwordssurprisal1gm,
         noun_unigram = surprisal1gm,
         pred_unigram = surprisal1gm + lexicalcategorypredicates + lexicalcategorypredicatessurprisal1gm
         ) |> 
  select(noun_lstmresid,pred_lstmresid,noun_unigram, pred_unigram, fctwd_lstmresid, fctwd_unigram) |> 
  gather(key="term", value="estimate") |> 
  separate(col=term, into=c("lexical_category", "term"), sep="_") |>
  mutate(language = lang,
         measure = ms)

#lex.labs <- c("function words", "nouns", "predicates")
#names(lex.labs) <- c("fctwd", "noun", "pred")
#ggplot(lexcat_betas, aes(x = estimate, y = term, colour = term, fill=term)) +
#  facet_grid(~ lexical_category, labeller = labeller(lexical_category = lex.labs)) +
#  geom_vline(xintercept = 0, color = "grey", linetype = "dotted") +
#  geom_point(alpha=0.2, position = position_jitter(w = 0, h = 0.1), show.legend = FALSE)+
#  labs(x = "Coefficient estimate", y = "") +
#  theme_bw() +
#  theme(text=element_text(size=18,  family="Times New Roman"), axis.text.x = element_text(size = 16), axis.text.y = element_text(size = 16))
```

Get absolute deviation difference between models by word
```{r beyond_freq}
word_mad_diff <- loo_preds |> filter(name %in% c("uni_surp", "lstm_surp_rd")) |> 
  group_by(name, test_word, lexical_category, aoa) |> summarise(mean(abs_dev)) |> 
  spread(key=name, value="mean(abs_dev)" ) |> 
  mutate(diff = uni_surp-lstm_surp_rd) |> 
  arrange(desc(diff)) |>
  mutate(language = lang,
         measure = ms)

#ggplot(data = word_mad_diff |> arrange(desc(diff))  %>% head(30) , 
#            aes(x = reorder(test_word,diff), y = diff, fill=lexical_category)) +
#  geom_bar(stat='identity') +
#  coord_flip()+
#  labs(x="", y="difference in absolute deviation") +
#  theme_bw() +
#  theme(text=element_text(size=18,  family="Times New Roman"), legend.title = element_text( size = 16), legend.text = element_text( size = 16), legend.position = c(0.7, 0.6), axis.text.x = element_text(size = 16), axis.text.y = element_text(size = 16))
```

by lexical category 
```{r lexcat_counts}
lexcat_mad_diff <- word_mad_diff |> group_by(lexical_category) |>
  summarise(mean_diff=mean(diff), n_lex =n()) |>
  mutate(language = lang,
         measure = ms)

lexcat_mad_diff
```


```{r collect_data3}

#first language
exp2_all_cv_results_resid <- cv_results
exp2_all_cv_results_pos_resid <- cv_results_pos

exp2_all_lexcat_betas_resid <- lexcat_betas
exp2_all_word_mad_diffs_resid <- word_mad_diff
exp2_all_lexcat_mad_diffs_resid <- lexcat_mad_diff

#all subsequent languages
#exp2_all_cv_results_resid <- exp2_all_cv_results_resid |> rbind(cv_results)
#exp2_all_cv_results_pos_resid <- exp2_all_cv_results_pos_resid |> rbind(cv_results_pos)

#exp2_all_lexcat_betas_resid <- exp2_all_lexcat_betas_resid |> rbind(lexcat_betas)
#exp2_all_word_mad_diffs_resid <- exp2_all_word_mad_diffs_resid |> rbind(word_mad_diff)
#exp2_all_lexcat_mad_diffs_resid <- exp2_all_lexcat_mad_diffs_resid |> rbind(lexcat_mad_diff)

```

STOP - REPEAT EXPERIMENT FOR NEXT LANGUAGE


```{r save_data1}
saveRDS(exp2_all_cv_results_resid, "./experiment-results/diss/exp2_all_cv_results_resid.rds" )
saveRDS(exp2_all_cv_results_pos_resid, "./experiment-results/diss/exp2_all_cv_results_pos_resid.rds" )

saveRDS(exp2_all_lexcat_betas_resid, "./experiment-results/diss/exp2_all_lexcat_betas_resid.rds" )
saveRDS(exp2_all_word_mad_diffs_resid, "./experiment-results/diss/exp2_all_word_mad_diffs_resid.rds" )
saveRDS(exp2_all_lexcat_mad_diffs_resid, "./experiment-results/diss/exp2_all_lexcat_mad_diffs_resid.rds" )
```



## For Australian beta extraction from cross validation models

For Australian English has no function word items. If you run into trouble getting the betas for this language, run  this code instead for all experiments
```{r betas}
get_betas <- function(n){
  model = models$model[n]
  result <- tidy(model[[1]]) |> 
      mutate(fold = n)
  return(result)
}

#models= loo_models |> filter(name=="all_full")  
models= loo_models |> filter(name=="lstm_surp_rd")  

models_betas = map(c(1:nrow(models)), get_betas) |> bind_rows()

lexcat_betas <- models_betas |> select(term, estimate, fold) |> spread(key=term, value=estimate) |>
  rename_with(removePunctuation) |>
  mutate(pred_surprisal = lstmsurprisal + lexicalcategorypredicates + lexicalcategorypredicateslstmsurprisal,
         noun_surprisal = lstmsurprisal,
         noun_frequency = allfrequency,
         pred_frequency = allfrequency + lexicalcategorypredicates + lexicalcategorypredicatesallfrequency,
         noun_concreteness = concreteness,
         pred_concreteness = concreteness + lexicalcategorypredicates + lexicalcategorypredicatesconcreteness
         ) |> 
  select(noun_surprisal,pred_surprisal,noun_frequency, pred_frequency, noun_concreteness, pred_concreteness) |> 
  gather(key="term", value="estimate") |> 
  separate(col=term, into=c("lexical_category", "term"), sep="_") |>
  mutate(language = lang,
         measure = ms)

lexcat_betas <- models_betas |> select(term, estimate, fold) |> spread(key=term, value=estimate) |>
  rename_with(removePunctuation) |>
  mutate(
         pred_lstmresid = lstmsurpresid + lexicalcategorypredicates + lexicalcategorypredicateslstmsurpresid,
         noun_lstmresid = lstmsurpresid,
         noun_unigram = surprisal1gm,
         pred_unigram = surprisal1gm + lexicalcategorypredicates + lexicalcategorypredicatessurprisal1gm
         ) |> 
  select(noun_lstmresid,pred_lstmresid,noun_unigram, pred_unigram) |> 
  gather(key="term", value="estimate") |> 
  separate(col=term, into=c("lexical_category", "term"), sep="_") |>
  mutate(language = lang,
         measure = ms)


#lex.labs <- c("nouns", "predicates")
#names(lex.labs) <- c("noun", "pred")
#p = ggplot(lexcat_betas, aes(x = estimate, y = term, colour = term, fill=term)) +
#  facet_grid(~ lexical_category, labeller = labeller(lexical_category = lex.labs)) +
#  geom_vline(xintercept = 0, color = "grey", linetype = "dotted") +
#  geom_point(alpha=0.2, position = position_jitter(w = 0, h = 0.1), show.legend = FALSE)+
#  labs(x = "Coefficient estimate", y = "") +
#  theme_bw() +
#  theme(text=element_text(size=18,  family="Times New Roman"), axis.text.x = element_text(size = 16), axis.text.y = element_text(size = 16))

```

