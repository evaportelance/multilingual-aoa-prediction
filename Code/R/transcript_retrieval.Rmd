---
title: "transcript_retrieval"
output: html_document
---
```{r}
require(devtools)
install_version("tm", version = "0.7-8", repos = "http://cran.us.r-project.org")
install.packages("devtools")
install.packages("hash")
install.packages("tm")
install.packages("filesstrings")
```

```{R}
knitr::opts_chunk$set(echo = TRUE)
library("childesr")
library("tm")
library("tidyverse")
library("filesstrings")
theme_set(theme_classic())
```

Enter the ISO 639-3 language code for the language of the desired transcripts.
Multiple language codes can be entered to get multi-language transcripts(e.g. "ara nld").
```{r set_transcript_language}
lang = "eng"
```


Gets all the transcript meta-data from CHILDES for the desired language.
```{r get_transcripts, eval=FALSE}
#child_names_eng <- c("Abe", "Adam", "Alex", "Anne", "Aran")
df.transcripts_eng <- get_transcripts() %>%
  filter(language == lang)
```

Get all the utterances for the selected transcripts.
```{r, eval=FALSE}
my_get_utterances = function(corpus_name, target_child_name) {
  return(get_utterances(corpus = corpus_name, target_child = target_child_name))
}
df.utterances_eng_all = df.transcripts_eng %>%
  group_by(corpus_name) %>%
  distinct(target_child_name)  %>%
  pmap(my_get_utterances) %>%
  reduce(rbind)
```

```{r}
write.csv(df.utterances_eng_all, file = "df_utterances_eng_all")
```
Given that there are multiple children with each name for different corpora, I need to only keep the one with the largest amount of tokens according to M & C's paper, which is equivalent to the one with the most utterances. So for each child name and for each different corpus, calculate the total number of utterances and filter to only keep the child for each name with the most utterances.
```{r, eval=FALSE}
df.utterances_eng_final = df.utterances_eng_all %>%
  ungroup() %>%
  group_by(target_child_name, corpus_name) %>% #
  mutate(nb_utterances = n()) %>%
  ungroup() %>%
  group_by(target_child_name) %>%
  mutate(max_nb_bychildname = max(nb_utterances)) %>%
  filter(nb_utterances == max_nb_bychildname) %>%
  select(-max_nb_bychildname) %>%
  ungroup()
```

For each utterance, remove all punctuation including apostrophes, following M & C's data description, and add final punctuation since they kept it in their cleaned transcripts. I don't think their model actually cares about the final punctuation since they end up removing it when they process the sentences, but given that they had both '.' and '?' in their example transcript, I have added both of these depending on the sentence type. Finally, I add '*CHI: ' or the equivalent speaker code for each utterance to the beginning of the string to match the formatting used by M & C. Their model does string matching on the speaker code to determine if an utterance was produced by the target child or not.
```{r, eval=FALSE}
df.CBL_strings_eng_final = df.utterances_eng_final %>%
  mutate(gloss_cleaned = ifelse(is.na(stem) | stem =="", NA, removePunctuation(gloss))) %>%
  mutate(finalpunc = ifelse(grepl("question", type, fixed=TRUE),
                            "?", ".")) %>%
  mutate(CBL_string = ifelse(!is.na(gloss_cleaned),
                             paste("*", speaker_code, ": ", gloss_cleaned, " ", finalpunc, sep=""), NA))
```

Gets the corpus names for the children in df.utterances_eng_final.
```{r, get_corpus_names}
corpus_names <-df.utterances_eng_final$corpus_name %>% 
  unique() %>% 
  append("Not_Available")
```


Creates a directory at a given path if it does not already exist.
```{r, create_dir_or_file}
create_dir_or_file  =  function (path) {
    if (!dir.exists(path)) {
      dir.create(path)
    }
  }
```


Sets up a directory structure of the form:
transcripts/[ISO language code]/[corpus name]
```{r, create_folder_lang}
  TRANSCRIPT_DIR_PATH <- "../../../Data/transcripts"
  create_dir_or_file(TRANSCRIPT_DIR_PATH)

  lang_dir_path <- paste(TRANSCRIPT_DIR_PATH, "/", lang, sep="")
  create_dir_or_file(lang_dir_path)

  corpus_paths <- lang_dir_path %>% 
    paste("/", corpus_names, sep="") %>% 
    lapply(create_dir_or_file)
  
  #for transcripts with no corpus names
  #create_dir_or_file(lang_dir_path)
```


Write a separate file for each child transcript.
```{r, eval=FALSE}  
my_write_CBL_transcripts <- function(df){
  child_name <- df$target_child_name[1]
  corpus_name <- df$corpus_name[1]
  if (is.na(corpus_name)) {
    corpus_name <- "not_available"
  }
  transcript_dir <- paste("../../../data/transcripts/", lang, "/", corpus_name, "/", child_name, ".capp", sep ="")
  if (!file.exists(transcript_dir)) {
    df %>%
    filter(!is.na(CBL_string)) %>%
    select(CBL_string) %>%
    write.table(., file=transcript_dir, quote = FALSE, col.names = FALSE, row.names = FALSE)
    return(df)
  }
}
df.CBL_strings_eng_final %>%
  select(target_child_name, CBL_string, corpus_name) %>%
  group_by(target_child_name) %>%
  do(my_write_CBL_transcripts(.))
```s
